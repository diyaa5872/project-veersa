{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "077510aa-86a0-4ebf-be7f-34bb8c0e0ed3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, expr\n",
    "import dlt\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import xxhash64\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_table\",\n",
    "    comment=\"Streaming silver table from bronze stage with transformations and SCD2 columns\"\n",
    ")\n",
    "def silver_incoming():\n",
    "    bronze_df = dlt.read_stream(\"bronze_stage\")\n",
    "    config_df = dlt.read(\"`unity-veersa`.config_tables.config_stage_to_silver\")\n",
    "    active_cols = config_df.filter(F.col(\"is_active\") == True).collect()\n",
    "\n",
    "    transformed_df = bronze_df\n",
    "    for col_meta in active_cols:\n",
    "        col_name = col_meta[\"column_name\"]\n",
    "        alias_name = col_meta[\"alias_name\"] or col_name\n",
    "        if col_name in bronze_df.columns:\n",
    "            col_expr = F.col(col_name)\n",
    "            if col_meta[\"apply_trim\"]:\n",
    "                col_expr = F.trim(col_expr)\n",
    "            if col_meta[\"apply_upper\"]:\n",
    "                col_expr = F.upper(col_expr)\n",
    "            transformed_df = transformed_df.withColumn(alias_name, col_expr)\n",
    "\n",
    "    transformed_df = transformed_df.withColumn(\"ingest_ts\", F.current_timestamp()) \\\n",
    "                                   .withColumn(\"record_source\", F.lit(\"bronze_stage\")) \\\n",
    "                                   .withColumn(\"rowhash\",xxhash64(*transformed_df.columns))\n",
    "\n",
    "    if \"city\" in transformed_df.columns:\n",
    "        transformed_df = transformed_df.withColumn(\"city\", F.initcap(F.col(\"city\")))\n",
    "    if \"zip_prefix\" in transformed_df.columns:\n",
    "        transformed_df = transformed_df.withColumn(\"zip_prefix\", F.lpad(F.col(\"zip_prefix\").cast(\"string\"), 5, \"0\"))\n",
    "    if \"customer_id\" in transformed_df.columns:\n",
    "        transformed_df = transformed_df.drop(\"customer_id\")\n",
    "    \n",
    "\n",
    "    return transformed_df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "stage_to_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
